# ReefLitÂ AIÂ Pipeline

> **Goal:** Continuously transform the fireâ€‘hose of coralâ€‘reef literature into queryable, upâ€‘toâ€‘date evidence graphs and dashboardsâ€” with endâ€‘toâ€‘end reproducibility.

---

## ğŸ—ºï¸ Highâ€‘Level Flow

```mermaid
flowchart TD
    subgraph Ingest
        A1[CrossRef API]
        A2[PubMed API]
        A3[bioRxiv RSS]
        A4[NOAA CoRIS CSV]
        A5[Springer RSS]
        A1 --> B[Raw JSONL]
        A2 --> B
        A3 --> B
        A4 --> B
        A5 --> B
    end

    subgraph Screening
        B --> C[Weakâ€‘SupervisionÂ Ruleâ€‘Matcher <br> (stressors.yml)]
        C --> D[Labelled JSONL]
    end

    subgraph Enrichment
        D --> E[PDF Fetcher  âœ  Text Extractor]
        E --> F[spaCy / scispaCy NER]
        D --> F
        F --> G[Embeddings (Sentenceâ€‘Transformers)]
    end

    subgraph Storage
        G --> H[FAISS VectorÂ DB]
        F --> I[PostgresÂ /Â DuckDB]
    end

    subgraph Synthesis
        H --> J[RAGÂ Q&A API]
        I --> K[Plots & KPIs]
        I --> L[Neo4j Knowledge Graph]
    end

    subgraph Serve
        J --> M[Dash/Streamlit Dashboard]
        K --> M
        L --> M
    end

    click stressors.yml "../stressors.yml" "Taxonomy"
```

---

## 1ï¸âƒ£ Ingest
| Component | Purpose | Notes |
|-----------|---------|-------|
| **`fetch.py`** | Harvest metadata (title, abstract, DOI, journal, year) from each source. | Rateâ€‘limited; retries with exponential backâ€‘off. |
| **Storage** | Append to `data/raw/YYYY-MM-DD.jsonl`. | Raw dump kept for provenance; never overwritten. |

### Data Sources
* CrossRef query: `coral reef` OR `scleractinia`
* PubMed Eâ€‘Utils search: mesh terms `coral reefs` + `2010:` current
* bioRxiv RSS filter: keyword `coral`
* NOAA CoRIS publications CSV (monthly)
* Springer **Coral Reefs** journal RSS

## 2ï¸âƒ£ Screening (Weak Supervision)
* **Ruleâ€‘Matcher**: spaCy pipeline loads `stressors.yml` to assign provisional multiâ€‘label tags (`warming`, `acidification`, etc.).
* **Confidence score** = (# matched keywords) Ã· (keywords per stressor).
* **Output** saved to `data/processed/screened.jsonl`.

> **Why weak supervision?**Â Â Bootstraps a usable corpus without hundreds of manual annotations; iterative activeâ€‘learning cycles will refine.

## 3ï¸âƒ£ Enrichment
| Step | Tooling | Output |
|------|---------|--------|
| **PDF Fetch** | Unpaywall + Publisher URLs; fallback to ScienceHub. | `pdfs/DOI.pdf` |
| **Text Extraction** | `PyMuPDF` to plaintext; fallback `GROBID` TEI. | `txt/DOI.txt` |
| **NER** | spaCy (`en_core_sci_lg`) + custom entities (`LOCATION`, `METHOD`, `INTERVENTION`). | token spans + JSONL |
| **Embeddings** | `sentence-transformers/all-mpnet-base-v2` on title+abstract. | `faiss/index.bin` |

## 4ï¸âƒ£ Storage
* **Postgres/DuckDB** stores metadata + NER output (easy SQL joins).
* **FAISS** provides fast vector similarity for RAG queries.
* **Neo4j** (optional) builds graph of `Reef â†” Stressor â†” Intervention`.

## 5ï¸âƒ£ Synthesis
* **KPIs**: count papers per stressor, per region, yearly trends.
* **Forest plots**: metaâ€‘analysis of effect sizes where extractable.
* **RAG Q&A**: Haystack pipeline pulls topâ€‘k similar embeddings + abstracts, feeds to OpenAI (or local LLM) to craft answer citations.

## 6ï¸âƒ£ Serve
* **Dashboard**: Dash/Plotly app shows KPIs, lets users ask our API, and downloads CSV.
* **API**: `/query?q="heat stress Western Pacific"&top_n=10` returns JSON with citations, scores.

---

## ğŸ”„ Automation
* **GitHub Actions** nightly workflow (`.github/workflows/pipeline.yml`):
  1. `fetch.py`Â â†’ commit raw JSONL artefact.
  2. `screen.py`Â â†’ commit processed JSONL.
  3. `enrich.py`Â â†’ push updated FAISS & DB dumps to cloudâ€‘storage.
  4. Trigger Render deploy webhook to refresh dashboard.

## ğŸ› ï¸ Local Development
```bash
conda env create -f environment.yml
conda activate reeflit
# Run pipeline endâ€‘toâ€‘end on a sample day
python pipeline/run_local.py --date 2025-04-29 --sample 500
# Launch dashboard
streamlit run app.py
```

## ğŸ”’ Data & Ethics
* **Licenses:** store DOIs only; PDFs fetched are for textâ€‘mining under fair use, never reâ€‘distributed.
* **Attribution:** Every dashboard claim links back to source DOI.
* **Transparency:** All weakâ€‘supervision rules & evaluation notebooks are public.

## ğŸ“ˆ Future Enhancements
1. Activeâ€‘learning UI for manual validation.
2. Fineâ€‘tuned SciBERT classifier to replace rules.
3. Automatic PRISMA diagram rendering per stressor.
4. Webhooks for email/Slack alerts when new highâ€‘impact papers appear.

---

_Questions?Â Â Open an issue or reach us on X/TwitterÂ [@ReefLitAI](https://twitter.com/reeflitai)._